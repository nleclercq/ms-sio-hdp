{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET HADOOP/SPARK - MS-SIO-2019 - API SNCF TRANSILIEN - PARTIE I & II\n",
    "## SPARK STRUCTURED STREAMING - KAFKA PRODUCER\n",
    "### P.Hamy, N.Leclercq, L.Poncet - MS-SIO-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "import xmltodict\n",
    "from collections import OrderedDict\n",
    "from kafka import KafkaProducer \n",
    "from task import *\n",
    "from api_transilien_tools import NotebookCellContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.ERROR, datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les infos de login relatives à l'API Transilien sont chargées depuis un fichier local nommé 'api_transilien_login.json' contenant le dictionnaire suivant (attention il est important de mettre login et  password entre \"quotes\" afin qu'ils soient interprétés comme des chaines de caractères):\n",
    "```\n",
    "{\n",
    "    login: \"xxxxxxx\",\n",
    "    password: \"xxxxxxx\"\n",
    "}\n",
    "```\n",
    "Vous pouvez créer ce ficher à l'aide de la cellule suivante. Il suffit de la convertir de 'Markdown' à 'Code' (cf. bar de menu du notebook) et de l'executer (pensez à changer le loggin et password :-) sinon, recommencer, l'option 'w+' écrase le fichier éxistant)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "credentials = {'login': \"xxxxxx\", 'password': \"xxxxx\"}\n",
    "with open('./api_transilien_login.json', 'w+', encoding='utf-8') as f:\n",
    "    json.dump(credentials, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TransilienApi** : classe d'interface de l'API SNCF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransilienApi(NotebookCellContent):\n",
    "    \n",
    "    def __init__(self, credentials_file, managed_stations=None, log_output=None):\n",
    "        NotebookCellContent.__init__(self, output=log_output)\n",
    "        self.managed_stations = managed_stations\n",
    "        self.trains_data = None\n",
    "        self.stations_by_code = None\n",
    "        self.stations_by_name = None\n",
    "        self.converter = None\n",
    "        self.stations_iterator = None\n",
    "        self.logins = None\n",
    "        self.passwords = None\n",
    "        self.logins_iterator = None\n",
    "        self.passwords_iterator = None\n",
    "        self.__load_credentials(credentials_file)\n",
    "\n",
    "    def __load_credentials(self, credentials_file):\n",
    "        with open(credentials_file, 'r', encoding='utf-8') as f:\n",
    "            self.credentials = json.load(f)\n",
    "        self.logins = self.credentials.get('logins', [self.credentials['login']])\n",
    "        self.passwords = self.credentials.get('passwords', [self.credentials['password']])\n",
    "        \n",
    "    def set_converter(self, converter):\n",
    "        assert(isinstance(converter, Converter))\n",
    "        self.converter = converter\n",
    "       \n",
    "    def set_managed_stations(self, managed_stations):\n",
    "        if  managed_stations == '*':\n",
    "            self.managed_stations = list(self.get_stations_code().keys())\n",
    "        else:\n",
    "            assert(isinstance(managed_stations, list))\n",
    "            assert(len(managed_stations))\n",
    "            self.managed_stations = managed_stations\n",
    "        \n",
    "    def load_stations_code(self, fullpath):\n",
    "        with open(fullpath, \"r\", encoding='utf-8') as f:\n",
    "            tmp = json.load(f)\n",
    "        self.stations_by_code = OrderedDict(sorted(tmp.items(), key=lambda x: x[0]))\n",
    "        \n",
    "    def get_stations_code(self):\n",
    "        return self.stations_by_code\n",
    "    \n",
    "    def __next_login(self):\n",
    "        try:\n",
    "            return next(self.logins_iterator)\n",
    "        except:\n",
    "            self.logins_iterator = iter(self.logins)\n",
    "            return next(self.logins_iterator)\n",
    "      \n",
    "    def __next_password(self):\n",
    "        try:\n",
    "            return next(self.passwords_iterator)\n",
    "        except:\n",
    "            self.passwords_iterator = iter(self.passwords)\n",
    "            return next(self.passwords_iterator)\n",
    "        \n",
    "    def __next_station(self):\n",
    "        try:\n",
    "            return next(self.stations_iterator)\n",
    "        except:\n",
    "            self.stations_iterator = iter(self.managed_stations)\n",
    "            return next(self.stations_iterator)\n",
    "        \n",
    "    def poll_next_station_data(self):\n",
    "        assert(self.managed_stations is not None)\n",
    "        assert(self.stations_by_code is not None)\n",
    "        trains_data = {}\n",
    "        for i in range(len(self.logins)):\n",
    "            station = self.__next_station()\n",
    "            self.debug(f\"API: polling data from station {station}...\")\n",
    "            url = f\"https://api.transilien.com/gare/{station}/depart\"\n",
    "            response = requests.get(url, auth=(self.__next_login(), self.__next_password()))\n",
    "            self.debug(f\"API: request response {response}\")\n",
    "            trains_data[station] = self.__parse_xml_data(station, response.content)\n",
    "        if self.converter is not None:\n",
    "            trains_data = self.converter.convert(trains_data)\n",
    "        return trains_data\n",
    "            \n",
    "    def poll_trains_data_backup(self):\n",
    "        assert(self.managed_stations is not None)\n",
    "        assert(self.stations_by_code is not None)\n",
    "        trains_data = {}\n",
    "        for station in self.managed_stations:\n",
    "            url = f\"https://api.transilien.com/gare/{station}/depart\"\n",
    "            response = requests.get(url, auth=(self.login, self.passwd))\n",
    "            self.debug(f\"API request response: {response}\")\n",
    "            trains_data[station] = self.__parse_xml_data(station, response.content)\n",
    "        if self.converter is not None:\n",
    "            trains_data = self.converter.convert(trains_data)\n",
    "        return trains_data\n",
    "    \n",
    "    def __parse_xml_data(self, station, xml_response):\n",
    "        station_trains_data = {\n",
    "            'station': {\n",
    "                'code':station, \n",
    "                'label':self.stations_by_code[station]['label'], \n",
    "                'latitude':self.stations_by_code[station]['latitude'], \n",
    "                'longitude':self.stations_by_code[station]['longitude']}, \n",
    "            'departures':[]\n",
    "        }\n",
    "        try:\n",
    "            xml2dict = xmltodict.parse(xml_response)\n",
    "            xml2dict_trains = xml2dict['passages']['train']\n",
    "            for entry in xml2dict_trains:\n",
    "                # project constraint: trains belonging to the 'managed Transilien line' only\n",
    "                # here we translate this constraint by selecting trains with 'known terminus' only\n",
    "                terminus_code = entry.get('term', None)\n",
    "                if terminus_code is None or terminus_code not in self.stations_by_code:\n",
    "                    continue\n",
    "                # ok, the current 'entry' is releated to  \n",
    "                train = {}\n",
    "                train['date'] = entry['date']['#text'].split(' ')[0]\n",
    "                train['time'] = entry['date']['#text'].split(' ')[1]\n",
    "                train['number'] = entry['num']\n",
    "                train['mission'] = entry['miss']\n",
    "                train['mode'] = entry['date']['@mode']\n",
    "                train['terminus'] = {'code':terminus_code, 'label':self.stations_by_code[terminus_code]}\n",
    "                station_trains_data['departures'].append(train)\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            station_trains_data['departures'] = []\n",
    "        return station_trains_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une classe **Converter** dont les classes filles ont pour rôle est de convertir les données vers différents formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Converter:\n",
    "    \n",
    "    def convert(trains_data):\n",
    "        raise Exception(\"Converter.convert: default impl. called!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JsonConverter** est un **Converter** dédié au format json..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonConverter(Converter):\n",
    "\n",
    "    def convert(self, trains_data):\n",
    "        assert(isinstance(trains_data, (dict, OrderedDict)))\n",
    "        departures = []\n",
    "        for station, station_data in trains_data.items():\n",
    "            for train_data in station_data['departures']:\n",
    "                time = f\"{train_data['time']}\"\n",
    "                date = '-'.join(train_data['date'].split('/')[::-1])\n",
    "                timestamp = f\"{date}T{time}:00.000Z\"\n",
    "                departure = {\n",
    "                    # station identifier (number)\n",
    "                    'station':int(station), \n",
    "                    # train identifier (string)\n",
    "                    'train': train_data['number'], \n",
    "                    # departure time (string)\n",
    "                    'timestamp':timestamp,\n",
    "                    # departure mode (string) \n",
    "                    'mode':train_data['mode'],\n",
    "                    # mission code (string)\n",
    "                    'mission':train_data['mission'],\n",
    "                    # terminus (i.e. station) identifier (number)\n",
    "                    'terminus':int(train_data['terminus']['code'])\n",
    "                } \n",
    "                departures.append(departure)\n",
    "        return departures      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KafkaProducerTask** : une task (i.e. thread avec message queue) qui gére le polling des données sur l'API SNCF et leur injection dans le streame Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KafkaProducerTask(Task, NotebookCellContent):\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "    def __init__(self, config):\n",
    "    # -------------------------------------------------------------------------------\n",
    "        Task.__init__(self, \"KafkaProducerTask\")\n",
    "        NotebookCellContent.__init__(self, \"KafkaProducerTask\")\n",
    "        self.config = config\n",
    "        # setup logging\n",
    "        self.last_clear_outputs_ts = time.time()\n",
    "        self.set_logging_level(logging.DEBUG)\n",
    "        self.debug(\"TSP:initializing...\")\n",
    "        # setup data polling & streaming\n",
    "        self.producer = None\n",
    "        self.__setup_api()\n",
    "        self.debug(\"TSP:`-> done!\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------------\n",
    "    def __setup_api(self):\n",
    "    # -------------------------------------------------------------------------------\n",
    "        # setup the SNCF API\n",
    "        credentials_file = self.config.get('credentials', './api_transilien_login.json')\n",
    "        self.api = TransilienApi(credentials_file, log_output=self.output)\n",
    "        self.api.set_converter(JsonConverter())\n",
    "        self.api.load_stations_code(\"./transilien_line_l_stations_by_code.json\")\n",
    "        self.api.set_managed_stations('*')\n",
    "        \n",
    "    # -------------------------------------------------------------------------------\n",
    "    def on_init(self):\n",
    "    # -------------------------------------------------------------------------------\n",
    "        # instanciate the KafkaProducer\n",
    "        self.debug(\"KafkaProducerTask: intializing KafkaProducer instance...\")\n",
    "        self.producer = KafkaProducer(\n",
    "                            client_id='transilien-producer-01',\n",
    "                            bootstrap_servers = self.config.get('bootstrap_servers', ['sandbox-hdp.hortonworks.com:6667']),\n",
    "                            value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "                            acks=0,\n",
    "                            api_version=(0, 10, 1)\n",
    "                        )\n",
    "        self.debug(\"`-> done!\")\n",
    "        # force call to handle_periodic_message (force data update)\n",
    "        self.handle_periodic_message()\n",
    "        # then setup ourself to poll data from the SNCF API at a given period (in seconds)\n",
    "        p = self.config.get('api_polling_period_in_seconds', 2.)\n",
    "        self.enable_periodic_message(p)\n",
    "        \n",
    "    # -------------------------------------------------------------------------------\n",
    "    def on_exit(self):\n",
    "    # -------------------------------------------------------------------------------\n",
    "        # close the KafkaProducer\n",
    "        self.debug(\"KafkaProducerTask: closing the KafkaProducer instance...\")\n",
    "        self.producer.close()\n",
    "        self.debug(\"`-> done!\")\n",
    "       \n",
    "    # -------------------------------------------------------------------------------\n",
    "    def clearOutputs(self):\n",
    "    # -------------------------------------------------------------------------------\n",
    "        # clear outputs (i.e. clear our 'mother notebook-cell')\n",
    "        clear_outputs_period = self.config.get('clear_outputs_period', 4)\n",
    "        if (time.time() - self.last_clear_outputs_ts) > clear_outputs_period:\n",
    "            self.clear_output()\n",
    "            self.last_clear_outputs_ts = time.time()\n",
    "            \n",
    "    # -------------------------------------------------------------------------------\n",
    "    def handle_periodic_message(self):\n",
    "    # -------------------------------------------------------------------------------\n",
    "        # asynchronous periodic job...\n",
    "        try:\n",
    "            # clear cell content (avoid cumiulating to mush log into the notebook cell)\n",
    "            #self.clearOutputs()\n",
    "            self.clear_output()\n",
    "            # do the job...\n",
    "            self.debug(\"KafkaProducerTask: polling data from the SNCF API...\")\n",
    "            t = time.time()\n",
    "            #departures = self.api.poll_trains_data()\n",
    "            departures = self.api.poll_next_station_data()\n",
    "            self.debug(f\"`-> obtained {len(departures)} train entries in {round(time.time() - t, 2)} s\")\n",
    "            self.debug(f\"KafkaProducerTask: injecting data into the Kafka topic '{self.config['topic']}'\")\n",
    "            t = time.time()\n",
    "            for departure in departures:\n",
    "                try:\n",
    "                    self.producer.send(self.config['topic'], departure)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            self.debug(f\"`-> took {round(time.time() - t, 2)} s\")\n",
    "        except Exception as e:\n",
    "            self.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_task_config = {\n",
    "    'bootstrap_servers': ['sandbox-hdp.hortonworks.com:6667'],\n",
    "    'topic': 'transilien-02',\n",
    "    'api_polling_period_in_seconds':2.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_task = KafkaProducerTask(producer_task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_task.start_asynchronously()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_task.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
