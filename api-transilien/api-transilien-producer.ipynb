{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNCF - OPEN DATA - API TRANSILIEN - \"PROCHAINS DEPARTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import xmltodict\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransilienApi:\n",
    "    \n",
    "    def __init__(self, login, password, managed_stations=None):\n",
    "        self.login = login\n",
    "        self.passwd = password\n",
    "        self.managed_stations = managed_stations\n",
    "        self.trains_data = None\n",
    "        self.stations_by_code = None\n",
    "        self.stations_by_name = None\n",
    "        self.converter = None\n",
    "    \n",
    "    def set_converter(self, converter):\n",
    "        assert(isinstance(converter, Converter))\n",
    "        self.converter = converter\n",
    "       \n",
    "    def set_managed_stations(self, managed_stations):\n",
    "        if  managed_stations == '*':\n",
    "            self.managed_stations = list(t.get_stations_code().keys())\n",
    "        else:\n",
    "            assert(isinstance(managed_stations, list))\n",
    "            assert(len(managed_stations))\n",
    "            self.managed_stations = managed_stations\n",
    "        \n",
    "    def load_stations_code(self, fullpath):\n",
    "        with open(fullpath, \"r\", encoding='utf-8') as f:\n",
    "            tmp = json.load(f)\n",
    "        self.stations_by_code = OrderedDict(sorted(tmp.items(), key=lambda x: x[0]))\n",
    "        \n",
    "    def get_stations_code(self):\n",
    "        return self.stations_by_code\n",
    "    \n",
    "    def poll_trains_data(self):\n",
    "        assert(self.managed_stations is not None)\n",
    "        assert(self.stations_by_code is not None)\n",
    "        trains_data = {}\n",
    "        for station in self.managed_stations:\n",
    "            url = f\"https://api.transilien.com/gare/{station}/depart\"\n",
    "            response = requests.get(url, auth=(self.login, self.passwd))\n",
    "            trains_data[station] = self.parse_xml_data(station, response.content)\n",
    "        if self.converter is not None:\n",
    "            trains_data = self.converter.convert(trains_data)\n",
    "        return trains_data\n",
    "    \n",
    "    def parse_xml_data(self, station, xml_response):\n",
    "        station_trains_data = {\n",
    "            'station': {\n",
    "                'code':station, \n",
    "                'label':self.stations_by_code[station]['label'], \n",
    "                'latitude':self.stations_by_code[station]['latitude'], \n",
    "                'longitude':self.stations_by_code[station]['longitude']}, \n",
    "            'departures':[]\n",
    "        }\n",
    "        try:\n",
    "            xml2dict = xmltodict.parse(xml_response)\n",
    "            xml2dict_trains = xml2dict['passages']['train']\n",
    "            for entry in xml2dict_trains:\n",
    "                # project constraint: real date/time only\n",
    "                #if entry['date']['@mode'] != 'R':\n",
    "                #    continue\n",
    "                # project constraint: trains belonging to the 'managed Transilien line' only\n",
    "                # here we translate this constraint by selecting trains with 'known terminus' only\n",
    "                terminus_code = entry.get('term', None)\n",
    "                if terminus_code is None or terminus_code not in self.stations_by_code:\n",
    "                    continue\n",
    "                # ok, the current 'entry' is releated to  \n",
    "                train = {}\n",
    "                train['date'] = entry['date']['#text'].split(' ')[0]\n",
    "                train['time'] = entry['date']['#text'].split(' ')[1]\n",
    "                train['number'] = entry['num']\n",
    "                train['mission'] = entry['miss']\n",
    "                train['terminus'] = {'code':terminus_code, 'label':self.stations_by_code[terminus_code]}\n",
    "                station_trains_data['departures'].append(train)\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            station_trains_data['departures'] = []\n",
    "        return station_trains_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les infos de login relatives à l'API Transilien sont chargées depuis un fichier local nommé 'api_transilien_login.json' contenant le dictionnaire suivant (attention il est important de mettre login et  password entre \"quotes\" afin qu'ils soient interprétés comme des chaines de caractères):\n",
    "```\n",
    "{\n",
    "    login: \"xxxxxxx\",\n",
    "    password: \"xxxxxxx\"\n",
    "}\n",
    "```\n",
    "Vous pouvez créer ce ficher à l'aide de la cellule suivante. Il suffit de la convertir de 'Markdown' à 'Code' (cf. bar de menu du notebook) et de l'executer (pensez à changer le loggin et password :-) sinon, recommencer, l'option 'w+' écrase le fichier éxistant)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "credentials = {'login': \"xxxxxx\", 'password': \"xxxxx\"}\n",
    "with open('./api_transilien_login.json', 'w+', encoding='utf-8') as f:\n",
    "    json.dump(credentials, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des credentials..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./api_transilien_login.json', 'r', encoding='utf-8') as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des gares d'intérêt (gares pour lesquelles sont souhaite obtenir les horaires de trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "managed_stations = [ \n",
    "    #'87384008', # PARIS SAINT-LAZARE (GARE SAINT-LAZARE)\n",
    "    '87381111'  # PONT CARDINET\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciation de la classe TransilienApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TransilienApi(credentials['login'], credentials['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des dictionnaires (code-gare <-> label-gare) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.load_stations_code(\"./transilien_line_l_stations_by_code.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_managed_stations('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requête de données temps réel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trains_data = t.poll_trains_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trains_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y'a plus qu'à pousser ça dans un message Kafka..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une classe 'Converter' dont les classes filles ont pour rôle est de convertir les données vers différents formats..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Converter:\n",
    "    \n",
    "    def convert(trains_data):\n",
    "        raise Exception(\"Converter.convert: default impl. called!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ProtobufConverter' est un 'Converter' dédié au format google protocol buffer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonConverter(Converter):\n",
    "\n",
    "    def convert(self, trains_data):\n",
    "        assert(isinstance(trains_data, (dict, OrderedDict)))\n",
    "        departures = []\n",
    "        for station, station_data in trains_data.items():\n",
    "            for train_data in station_data['departures']:\n",
    "                time = f\"{train_data['time']}\"\n",
    "                date = '-'.join(train_data['date'].split('/')[::-1])\n",
    "                timestamp = f\"{date}T{time}:00.000Z\"\n",
    "                departure = {\n",
    "                    'station':int(station),\n",
    "                    'timestamp':timestamp,\n",
    "                    'train': train_data['number']\n",
    "                } \n",
    "                departures.append(departure)\n",
    "        return departures      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attachons un 'ProtobufConverter' à notre instance de 'TransilienApi'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_converter(JsonConverter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good... y'a plus qu'à pousser 'pb_msg' dans Kafka... (en tant que bunch d'octets ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "    client_id='transilien-producer-01',\n",
    "    bootstrap_servers=['sandbox-hdp.hortonworks.com:6667'],\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "    acks=0,\n",
    "    api_version=(0, 10, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"transilien-02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1000):\n",
    "    departures = t.poll_trains_data()\n",
    "    for departure in departures:\n",
    "        try:\n",
    "            producer.send(topic, departure)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
